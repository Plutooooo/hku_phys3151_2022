{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "to model and reveal the force of gravity.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMawlP8CgHaB+gkPH4UThy0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Plutooooo/hku_phys3151_2022/blob/main/multivariate-linear-regression/to_model_and_reveal_the_force_of_gravity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using polynomial regression to model and reveal the force of gravity"
      ],
      "metadata": {
        "id": "aqWz9kqbl9YX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will take a look at a simple example: the force of gravity on a falling object. The formula for the location of a falling object is:\n",
        "\n",
        "\\begin{eqnarray}\n",
        "y=X_{0}+V_{0}t-\\frac{1}{2}gt^{2}\n",
        "\\end{eqnarray}\n",
        "\n",
        "where $X_{0}$ is the initial location of the object, i.e. its initial height.\n",
        "$V_{0}$ is the initial velocity (or speed) of the object when it is at this initial position. $t$ is the time after the object was dropped. $g$ is the force of gravity, which is an acceleration of approximately 9.8 $m/s^{2}$. This is actually a constant not a variable like all of the others (unless we are dropping an object on different planets, which are not). It is negative because the force of gravity is downward, from a positive location value toward zero."
      ],
      "metadata": {
        "id": "nXL58ogzmONQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we will create a Python function to calculate the location of a falling object"
      ],
      "metadata": {
        "id": "jo98J0Dro2yc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def location(x_0, v_0, t):\n",
        "    return x_0 + v_0*t - (9.8/2)*t**2"
      ],
      "metadata": {
        "id": "qWUscPHgo6Yq"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we use this function to create a dataset and save it in a CSV file"
      ],
      "metadata": {
        "id": "B4tnqItmpCii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import random\n",
        "import math\n",
        "random.seed\n",
        "with open('gravity_location_data.csv', mode='w') as gravity_file:\n",
        "    gravity_writer = csv.writer(gravity_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "    gravity_writer.writerow(['initial_position', 'initial_velocity', 'mass', 'time', 'location'])\n",
        "    for i in range (0, 10000):\n",
        "        initial_position = random.randrange(1, 10000)\n",
        "        initial_velocity = random.randrange(1, 100)\n",
        "        mass = random.randrange(1, 1000)\n",
        "        time = random.randrange(1, 100)\n",
        "        gravity_writer.writerow([initial_position, initial_velocity, mass, time, location(initial_position, initial_velocity, time)])"
      ],
      "metadata": {
        "id": "nMhKhvw3pHpY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What we are doing here is creating 10,000 examples, using randomized values for all of our variables, then calculating the location at a certain (randomly selected) time."
      ],
      "metadata": {
        "id": "TmFDIoOgpOLH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "df = pd.read_csv('/content/gravity_location_data.csv')\n",
        "print(df)"
      ],
      "metadata": {
        "id": "Hx52Kebbp7Wc",
        "outputId": "b57d9ae4-cef2-4786-c323-d6892d347555",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      initial_position  initial_velocity  mass  time  location\n",
            "0                 4889                16   127    85  -29153.5\n",
            "1                  969                78   352    77  -22077.1\n",
            "2                 1450                19   111     8    1288.4\n",
            "3                 3651                71   332     9    3893.1\n",
            "4                   44                40   124    11    -108.9\n",
            "...                ...               ...   ...   ...       ...\n",
            "9995              5233                26   120    25    2820.5\n",
            "9996              2704                28   923    45   -5958.5\n",
            "9997              5072                76   514    72  -14857.6\n",
            "9998              6700                 5   232    69  -16283.9\n",
            "9999              2724                33   648    84  -29078.4\n",
            "\n",
            "[10000 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['initial_velocity_time']=df['initial_velocity']*df['time']\n",
        "df['time^2']=df['time']^2\n",
        "print(df)"
      ],
      "metadata": {
        "id": "G9Q75xxHwtqY",
        "outputId": "4ef14628-d408-4344-9765-b2a150980eaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      initial_position  initial_velocity  ...  initial_velocity_time  time^2\n",
            "0                 4889                16  ...                   1360      87\n",
            "1                  969                78  ...                   6006      79\n",
            "2                 1450                19  ...                    152      10\n",
            "3                 3651                71  ...                    639      11\n",
            "4                   44                40  ...                    440       9\n",
            "...                ...               ...  ...                    ...     ...\n",
            "9995              5233                26  ...                    650      27\n",
            "9996              2704                28  ...                   1260      47\n",
            "9997              5072                76  ...                   5472      74\n",
            "9998              6700                 5  ...                    345      71\n",
            "9999              2724                33  ...                   2772      86\n",
            "\n",
            "[10000 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we scale the data"
      ],
      "metadata": {
        "id": "9OUYH7aIyIJL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.to_numpy()\n",
        "X = [[df[:,0].reshape((-1, 1)),df[:,5].reshape((-1, 1)),df[:,6].reshape((-1, 1))]]\n",
        "y = df[:,4].reshape((-1, 1))\n",
        "print(X)"
      ],
      "metadata": {
        "id": "6NRbgEH3wGcW",
        "outputId": "536062a6-d992-4aa1-bdb1-8e491583edf8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[array([[4889.],\n",
            "       [ 969.],\n",
            "       [1450.],\n",
            "       ...,\n",
            "       [5072.],\n",
            "       [6700.],\n",
            "       [2724.]]), array([[1360.],\n",
            "       [6006.],\n",
            "       [ 152.],\n",
            "       ...,\n",
            "       [5472.],\n",
            "       [ 345.],\n",
            "       [2772.]]), array([[87.],\n",
            "       [79.],\n",
            "       [10.],\n",
            "       ...,\n",
            "       [74.],\n",
            "       [71.],\n",
            "       [86.]])]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we define functions for cost funciton and gradient descent."
      ],
      "metadata": {
        "id": "Prd7EH5T0XqZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def  computeCost(theta,X,y):\n",
        "    m = float(len(y))\n",
        "    \n",
        "    predictions = X.dot(theta)\n",
        "    cost = (1/(2*m)) * np.sum(np.square(predictions-y))\n",
        "    return cost"
      ],
      "metadata": {
        "id": "mU_Rqzl00UU0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(X,y,theta,alpha=0.1,iterations=200):\n",
        "    m = float(len(y))\n",
        "    cost_history = np.zeros(iterations)\n",
        "    theta_history = np.zeros((iterations,2))\n",
        "    for it in range(iterations):\n",
        "        \n",
        "        prediction = np.dot(X,theta)\n",
        "        theta = theta -(1/m)*alpha*( X.T.dot((prediction - y)))\n",
        "        theta_history[it,:] = theta.T\n",
        "        cost_history[it]  = computeCost(theta,X,y)\n",
        "        \n",
        "    return theta, cost_history, theta_history"
      ],
      "metadata": {
        "id": "UHUgK7hy0grw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alpha =0.1\n",
        "n_iter = 200\n",
        "\n",
        "theta = np.random.randn(3,1)\n",
        "print(theta)\n",
        "\n",
        "print(computeCost(theta,X,y))\n",
        "\n",
        "theta,cost_history,theta_history = gradient_descent(X,y,theta,alpha,n_iter)\n",
        "\n",
        "print('Theta0:          {:0.3f},\\nTheta1:          {:0.3f}'.format(theta[0][0],theta[1][0],theta[2][0]))\n",
        "print('Final cost/MSE:  {:0.3f}'.format(cost_history[-1]))\n",
        "\n",
        "plt.plot(cost_history)\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"$J(\\Theta)$\")\n",
        "plt.title(\"Cost function using Gradient Descent\")\n",
        "c=[]\n",
        "print('theta_history is',theta_history)\n",
        "print(theta_history[0])\n",
        "for i in range(len(theta_history)):\n",
        "    c.append([theta_history[i][0],theta_history[i][1]])\n",
        "print(c)"
      ],
      "metadata": {
        "id": "mIl42aua0m-6",
        "outputId": "5d94d48c-1736-45a2-bd08-41c3e74bb9cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1.08353918]\n",
            " [-0.58949003]\n",
            " [-0.71444054]]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-0e33056c90ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputeCost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcost_history\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-99aa1247e26b>\u001b[0m in \u001b[0;36mcomputeCost\u001b[0;34m(theta, X, y)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'dot'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "scaler = preprocessing.RobustScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "print(X_scaled)\n",
        "print(scaler)"
      ],
      "metadata": {
        "id": "Y6Rp0NMzzTxV",
        "outputId": "8c6029de-b0e0-4b19-8238-3becca348274",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-eb6e60bad508>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRobustScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    850\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 852\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    853\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1491\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1492\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1493\u001b[0;31m             \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"allow-nan\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1494\u001b[0m         )\n\u001b[1;32m   1495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    794\u001b[0m             raise ValueError(\n\u001b[1;32m    795\u001b[0m                 \u001b[0;34m\"Found array with dim %d. %s expected <= 2.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m                 \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    797\u001b[0m             )\n\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found array with dim 4. RobustScaler expected <= 2."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have our data in a CSV file, we import it"
      ],
      "metadata": {
        "id": "SvRWbcLRp0vv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "gravity_data = pd.read_csv('gravity_location_data.csv')\n",
        "df_location = pd.DataFrame(gravity_data)"
      ],
      "metadata": {
        "id": "DYFVtgLWp5bZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This data will not actually be linear but scitkit-learn gives us the ability modify the data so that it can be trained as a LinearRegression model, while taking into account that it is actually a polynomial."
      ],
      "metadata": {
        "id": "wDxEyDO0qiJn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "def split_data(data, target_name):\n",
        "    y = data[target_name]\n",
        "    X = data.drop(target_name, axis=1)\n",
        "    return train_test_split(X, y, test_size=0.2, random_state=30)"
      ],
      "metadata": {
        "id": "AeM_DPlEqvT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from math import sqrt\n",
        "def train_eval_poly(X_train, X_test, y_train, y_test):\n",
        "    regression_model = LinearRegression() \n",
        "    \n",
        "    poly = PolynomialFeatures(degree=2)\n",
        "    X_train_transform = poly.fit_transform(X_train)\n",
        "    X_test_transform = poly.fit_transform(X_test)\n",
        "    \n",
        "    regression_model.fit(X_train_transform, y_train)\n",
        "    \n",
        "    print(poly.fit(X_train).get_feature_names_out(X_train.columns))\n",
        "    \n",
        "    y_pred = regression_model.predict(X_test_transform)\n",
        "    print(\"R2: \\t\", r2_score(y_test, y_pred))\n",
        "    print(\"RMSE: \\t\", sqrt(mean_squared_error(y_test, y_pred)))\n",
        "    print(\"MAE: \\t\", mean_absolute_error(y_test, y_pred))\n",
        "    \n",
        "    return regression_model"
      ],
      "metadata": {
        "id": "_lCqlyeLqxK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we train the model with this code\n"
      ],
      "metadata": {
        "id": "1O7WPekfrBfa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_split = split_data(df_location, 'location')\n",
        "lrModel = train_eval_poly(*df_split)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtPwrqlhrGq9",
        "outputId": "90ecd075-908c-4bb4-f422-a42ba39a7f11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['1' 'initial_position' 'initial_velocity' 'mass' 'time'\n",
            " 'initial_position^2' 'initial_position initial_velocity'\n",
            " 'initial_position mass' 'initial_position time' 'initial_velocity^2'\n",
            " 'initial_velocity mass' 'initial_velocity time' 'mass^2' 'mass time'\n",
            " 'time^2']\n",
            "R2: \t 1.0\n",
            "RMSE: \t 5.988338170149552e-09\n",
            "MAE: \t 5.1550259847488174e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the $R^{2}$ value is 1.0. Also, the root mean squared error (RMSE) and mean absolute error (MAE) are tiny. At this scale that is minuscule, essentially zero."
      ],
      "metadata": {
        "id": "2iAbANPFrToZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let’s look at the exponents on our model, which are the exponents on the polynomial equation the model is using to make predictions"
      ],
      "metadata": {
        "id": "KScqUEX9rrAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lrModel.coef_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVXhE2JDrtug",
        "outputId": "9d9e5514-f3c7-429a-c8d3-5dac416b152b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.00000000e+00,  1.00000000e+00, -1.24161324e-13, -1.40331106e-13,\n",
              "       -6.83076701e-14, -2.22044605e-16, -2.56739074e-16,  2.77555756e-17,\n",
              "        5.22151766e-16, -6.07169480e-15,  1.86027409e-15,  1.00000000e+00,\n",
              "        1.04083409e-16,  9.15933995e-16, -4.90000000e+00])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This gives us coefficients correspond to each of the fifteen features from above. The first value (0.00000000e+00, or 0) is the coefficient for the value 1. That would be hanging constant with no variable, a constant value always added to the equation, except that the coefficient is zero so there is no constant value added to our result. The second value from our array ( 1.00000000e+00, or 1) is the coefficient on “initial_position.” And in fact, in our original equation, we have the initial velocity ($X_{0}$) with a coefficient of one.\n",
        "\n",
        "<br>\n",
        "\n",
        "Most of our other coefficients are essentially zero, and tell us that these factors are irrelevant to predicting the location, but we do have a few that are not. The twelfth in our list is also a coefficient of 1, which corresponds to ‘initial_velocity time,’ or initial velocity multiplied by time. Again, we have this factor in our original equation, which appears as $V_{0}t$.\n",
        "\n",
        "<br>\n",
        "\n",
        "Finally, the very last value is -4.9, which is the coefficient corresponding to ‘time ^ 2.’ Note that this also appears in our original equation as $\\frac{1}{2}gt^{2}$. But we said earlier that $g$ is approximately 9.8, and $-\\frac{1}{2} * 9.8 = -4.9$. So this also corresponds with our original equation.\n",
        "\n",
        "<br>\n",
        "\n",
        "There are two very interesting final points to be made here. First, the resulting model found the mass to be irrelevant to making the prediction, which is correct. Second, the machine learning algorithm was able to derive the gravitational acceleration constant g, or at least determine the value of the entire coefficient $(-\\frac{1}{2} * 9.8)$ which includes $g$."
      ],
      "metadata": {
        "id": "VkqwE4eXsBLE"
      }
    }
  ]
}